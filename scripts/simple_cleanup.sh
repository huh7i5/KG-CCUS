#!/bin/bash

# ç®€å•çš„GPUæ¸…ç†è„šæœ¬
echo "ğŸ§¹ æ¸…ç†GPUå†…å­˜ä¸­..."

# æŸ¥æ‰¾å¹¶ç»ˆæ­¢å¯èƒ½å ç”¨GPUçš„Pythonè¿›ç¨‹
echo "ğŸ” æŸ¥æ‰¾å ç”¨GPUçš„Pythonè¿›ç¨‹..."

# è·å–æ‰€æœ‰python3 main.pyè¿›ç¨‹å¹¶ç»ˆæ­¢
PIDS=$(pgrep -f "python3 main.py" 2>/dev/null)
if [ ! -z "$PIDS" ]; then
    echo "ğŸ“‹ å‘ç°ä»¥ä¸‹è¿›ç¨‹: $PIDS"
    echo "ğŸ”„ æ­£åœ¨ç»ˆæ­¢è¿›ç¨‹..."

    # ä¼˜é›…ç»ˆæ­¢
    echo "$PIDS" | xargs -r kill -TERM 2>/dev/null
    sleep 2

    # æ£€æŸ¥æ˜¯å¦è¿˜æœ‰è¿›ç¨‹å­˜åœ¨ï¼Œå¦‚æœæœ‰åˆ™å¼ºåˆ¶ç»ˆæ­¢
    REMAINING_PIDS=$(pgrep -f "python3 main.py" 2>/dev/null)
    if [ ! -z "$REMAINING_PIDS" ]; then
        echo "âš¡ å¼ºåˆ¶ç»ˆæ­¢å‰©ä½™è¿›ç¨‹..."
        echo "$REMAINING_PIDS" | xargs -r kill -KILL 2>/dev/null
        sleep 1
    fi

    echo "âœ… Pythonè¿›ç¨‹å·²æ¸…ç†"
else
    echo "âœ… æœªå‘ç°éœ€è¦æ¸…ç†çš„Pythonè¿›ç¨‹"
fi

# æ¸…ç†PyTorchç¼“å­˜ï¼ˆå¦‚æœå¯èƒ½ï¼‰
echo "ğŸ§¹ æ¸…ç†PyTorch GPUç¼“å­˜..."
python3 -c "
import sys
try:
    import torch
    if torch.cuda.is_available():
        torch.cuda.empty_cache()
        torch.cuda.synchronize()
        print('âœ… PyTorch GPUç¼“å­˜å·²æ¸…ç†')
    else:
        print('â„¹ï¸  CUDAä¸å¯ç”¨ï¼Œè·³è¿‡ç¼“å­˜æ¸…ç†')
except ImportError:
    print('â„¹ï¸  PyTorchæœªå®‰è£…ï¼Œè·³è¿‡ç¼“å­˜æ¸…ç†')
except Exception as e:
    print(f'âš ï¸  ç¼“å­˜æ¸…ç†è­¦å‘Š: {e}')
" 2>/dev/null

# æ˜¾ç¤ºGPUçŠ¶æ€
echo "ğŸ“Š å½“å‰GPUçŠ¶æ€:"
nvidia-smi --query-gpu=memory.used,memory.total --format=csv,noheader,nounits 2>/dev/null | while read line; do
    used=$(echo $line | cut -d',' -f1 | xargs)
    total=$(echo $line | cut -d',' -f2 | xargs)
    echo "  GPUå†…å­˜: ${used}MB / ${total}MB"
done

echo "ğŸ‰ GPUæ¸…ç†å®Œæˆï¼"