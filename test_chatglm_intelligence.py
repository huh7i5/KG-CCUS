#!/usr/bin/env python3
"""
æµ‹è¯•ChatGLMæ™ºèƒ½å›å¤åŠŸèƒ½ - å®Œæ•´çš„çŸ¥è¯†å›¾è°±å¢å¼ºæ™ºèƒ½é—®ç­”æµç¨‹
éªŒè¯ä»NER -> å›¾è°±æ£€ç´¢ -> promptæ„å»º -> ChatGLMæ¨ç† -> æ™ºèƒ½å›å¤çš„å…¨æµç¨‹
"""

import sys
import os
sys.path.append('server')
sys.path.append('server/app')

def test_complete_knowledge_graph_flow():
    """æµ‹è¯•å®Œæ•´çš„çŸ¥è¯†å›¾è°±å¢å¼ºæ™ºèƒ½é—®ç­”æµç¨‹"""
    print("ğŸš€ æµ‹è¯•å®Œæ•´çš„çŸ¥è¯†å›¾è°±å¢å¼ºæ™ºèƒ½é—®ç­”æµç¨‹")
    print("=" * 70)

    try:
        from app.utils.chat_glm import stream_predict

        # CCUSä¸“ä¸šé—®é¢˜æµ‹è¯•ç”¨ä¾‹
        test_cases = [
            {
                "query": "ä»€ä¹ˆæ˜¯CCUSæŠ€æœ¯ï¼Ÿ",
                "expectation": "åº”è¯¥åŒ…å«çŸ¥è¯†å›¾è°±ä¿¡æ¯å’ŒChatGLMæ™ºèƒ½ç”Ÿæˆçš„å›ç­”"
            },
            {
                "query": "åŒ—äº¬åœ°åŒºé€‚åˆä»€ä¹ˆCCUSæŠ€æœ¯ï¼Ÿ",
                "expectation": "åº”è¯¥ç»“åˆåœ°ç†å’ŒæŠ€æœ¯ä¿¡æ¯ç”Ÿæˆä¸“ä¸šå›ç­”"
            },
            {
                "query": "CCUSæŠ€æœ¯çš„æˆæœ¬å¦‚ä½•ï¼Ÿ",
                "expectation": "åº”è¯¥åŒ…å«æˆæœ¬åˆ†æå’ŒæŠ•èµ„ä¿¡æ¯"
            },
            {
                "query": "ç¢³æ•é›†æŠ€æœ¯çš„å·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
                "expectation": "åº”è¯¥è¯¦ç»†ä»‹ç»æŠ€æœ¯åŸç†"
            }
        ]

        results = []

        for i, test_case in enumerate(test_cases):
            print(f"\nğŸ“ æµ‹è¯•æ¡ˆä¾‹ {i+1}: {test_case['query']}")
            print(f"ğŸ¯ é¢„æœŸ: {test_case['expectation']}")
            print("-" * 50)

            try:
                responses = []
                # æ”¶é›†æµå¼å“åº”
                for response_data in stream_predict(test_case['query'], []):
                    if isinstance(response_data, bytes):
                        response_data = response_data.decode('utf-8')
                    responses.append(response_data)

                    # é™åˆ¶æ”¶é›†æ•°é‡ï¼Œé¿å…æ— é™å¾ªç¯
                    if len(responses) >= 3:
                        break

                if responses:
                    # è§£ææœ€åä¸€ä¸ªå“åº”
                    import json
                    try:
                        last_response = json.loads(responses[-1])
                        final_answer = last_response.get('updates', {}).get('response', '')

                        print(f"âœ… è·å¾—å›ç­”: {final_answer[:200]}...")

                        # è´¨é‡è¯„ä¼°
                        quality_score = assess_response_quality(test_case['query'], final_answer)
                        print(f"ğŸ“Š è´¨é‡è¯„ä¼°: {quality_score}")

                        results.append({
                            'query': test_case['query'],
                            'response': final_answer,
                            'quality': quality_score,
                            'success': True
                        })

                    except json.JSONDecodeError:
                        print(f"âš ï¸ å“åº”æ ¼å¼è§£æå¤±è´¥: {responses[-1][:100]}...")
                        results.append({
                            'query': test_case['query'],
                            'response': str(responses[-1])[:200],
                            'quality': {'valid': False},
                            'success': False
                        })
                else:
                    print("âŒ æ²¡æœ‰æ”¶åˆ°ä»»ä½•å“åº”")
                    results.append({
                        'query': test_case['query'],
                        'response': None,
                        'quality': {'valid': False},
                        'success': False
                    })

            except Exception as e:
                print(f"âŒ æµ‹è¯•å¤±è´¥: {e}")
                import traceback
                traceback.print_exc()
                results.append({
                    'query': test_case['query'],
                    'response': None,
                    'quality': {'valid': False, 'error': str(e)},
                    'success': False
                })

        # æ€»ç»“æµ‹è¯•ç»“æœ
        print("\n" + "=" * 70)
        print("ğŸ“Š æµ‹è¯•ç»“æœæ€»ç»“")
        print("=" * 70)

        successful_tests = sum(1 for r in results if r['success'])
        total_tests = len(results)

        print(f"âœ… æˆåŠŸç‡: {successful_tests}/{total_tests} ({successful_tests/total_tests*100:.1f}%)")

        for result in results:
            status = "âœ…" if result['success'] else "âŒ"
            print(f"{status} {result['query']}")
            if result['success'] and result['quality'].get('chatglm_generated'):
                print(f"   ğŸ¤– ChatGLMæ™ºèƒ½å›å¤: {'æ˜¯' if result['quality']['chatglm_generated'] else 'å¦'}")
                print(f"   ğŸ“š åŒ…å«çŸ¥è¯†å›¾è°±ä¿¡æ¯: {'æ˜¯' if result['quality']['has_knowledge'] else 'å¦'}")
                print(f"   ğŸ¯ å›ç­”ç›¸å…³æ€§: {'é«˜' if result['quality']['relevant'] else 'ä½'}")

        return results

    except Exception as e:
        print(f"âŒ å®Œæ•´æµç¨‹æµ‹è¯•å¤±è´¥: {e}")
        import traceback
        traceback.print_exc()
        return []

def assess_response_quality(query, response):
    """è¯„ä¼°å›ç­”è´¨é‡"""
    if not response:
        return {'valid': False, 'reason': 'No response'}

    quality = {
        'valid': True,
        'length': len(response),
        'has_knowledge': False,
        'relevant': False,
        'chatglm_generated': False,
        'structured': False
    }

    # æ£€æŸ¥æ˜¯å¦åŒ…å«çŸ¥è¯†å›¾è°±ä¿¡æ¯
    knowledge_indicators = ['åŸºäº', 'æ ¹æ®', 'çŸ¥è¯†å›¾è°±', 'ç›¸å…³ä¿¡æ¯', 'ä¸“ä¸š']
    quality['has_knowledge'] = any(indicator in response for indicator in knowledge_indicators)

    # æ£€æŸ¥ç›¸å…³æ€§
    query_keywords = ['ccus', 'ç¢³æ•é›†', 'ç¢³å‚¨å­˜', 'ç¢³åˆ©ç”¨', 'æŠ€æœ¯', 'æˆæœ¬', 'åŸç†']
    relevant_keywords = [kw for kw in query_keywords if kw in query.lower()]
    if relevant_keywords:
        quality['relevant'] = any(kw in response.lower() for kw in relevant_keywords)
    else:
        quality['relevant'] = True  # å¦‚æœæ²¡æœ‰ç‰¹å®šå…³é”®è¯ï¼Œé»˜è®¤ç›¸å…³

    # æ£€æŸ¥æ˜¯å¦æ˜¯ChatGLMç”Ÿæˆçš„æ™ºèƒ½å›å¤ï¼ˆä¸æ˜¯æ¨¡æ¿å“åº”ï¼‰
    template_indicators = [
        'æ¨¡æ¿å“åº”', 'template', 'é¢„è®¾å›ç­”', 'æ ‡å‡†å›å¤',
        'æˆ‘ç†è§£æ‚¨æƒ³äº†è§£', 'è¿™æ˜¯ä¸€ä¸ªå¾ˆå¥½çš„é—®é¢˜', 'è¯·ç¨ç­‰ï¼Œæˆ‘æ­£åœ¨ä¸ºæ‚¨æŸ¥æ‰¾'
    ]
    quality['chatglm_generated'] = not any(indicator in response for indicator in template_indicators)

    # æ£€æŸ¥æ˜¯å¦ç»“æ„åŒ–
    structure_indicators = ['**', 'â€¢', '\n', '1.', '2.', 'ä¸€ã€', 'äºŒã€']
    quality['structured'] = any(indicator in response for indicator in structure_indicators)

    # æ£€æŸ¥å›ç­”é•¿åº¦æ˜¯å¦åˆç†
    quality['length_adequate'] = 50 <= len(response) <= 2000

    return quality

def test_simple_chatglm_directly():
    """ç›´æ¥æµ‹è¯•SimpleChatGLMï¼ŒéªŒè¯tokenizerä¿®å¤æ•ˆæœ"""
    print("\nğŸ§ª ç›´æ¥æµ‹è¯•SimpleChatGLM")
    print("=" * 50)

    try:
        from app.utils.simple_chat import SimpleChatGLM

        model_path = "/fast/zwj/ChatGLM-6B/weights"
        chat_glm = SimpleChatGLM(model_path, memory_optimize=True)

        if chat_glm.load_model():
            print("âœ… ChatGLMæ¨¡å‹åŠ è½½æˆåŠŸ")

            test_query = "è¯·ä»‹ç»CCUSæŠ€æœ¯çš„åŸºæœ¬åŸç†"
            print(f"ğŸ“ æµ‹è¯•é—®é¢˜: {test_query}")

            try:
                for response, history in chat_glm.stream_chat(test_query, []):
                    print(f"ğŸ¤– ChatGLMå›ç­”: {response[:150]}...")

                    # æ£€æŸ¥æ˜¯å¦çœŸçš„æ˜¯ChatGLMç”Ÿæˆçš„
                    if "chatglm" in response.lower() or len(response) > 100:
                        print("âœ… ç¡®è®¤æ˜¯ChatGLMæ™ºèƒ½ç”Ÿæˆçš„å›ç­”")
                        return True
                    else:
                        print("âš ï¸ å¯èƒ½ä»åœ¨ä½¿ç”¨æ¨¡æ¿å“åº”")
                        return False
                    break
            except Exception as e:
                print(f"âŒ ChatGLMè°ƒç”¨å¤±è´¥: {e}")
                return False
        else:
            print("âŒ ChatGLMæ¨¡å‹åŠ è½½å¤±è´¥")
            return False

    except Exception as e:
        print(f"âŒ SimpleChatGLMæµ‹è¯•å¤±è´¥: {e}")
        return False

def main():
    """ä¸»æµ‹è¯•å‡½æ•°"""
    print("ğŸ¯ ChatGLMæ™ºèƒ½å›å¤åŠŸèƒ½éªŒè¯æµ‹è¯•")
    print("ğŸ¯ ç›®æ ‡ï¼šéªŒè¯çœŸæ­£çš„ChatGLMæ™ºèƒ½å›å¤ï¼Œè€Œéæ¨¡æ¿å“åº”")
    print("ğŸ¯ æµç¨‹ï¼šNER â†’ å›¾è°±æ£€ç´¢ â†’ promptæ„å»º â†’ ChatGLMæ¨ç† â†’ æ™ºèƒ½å›å¤")
    print("=" * 70)

    # æµ‹è¯•1: ç›´æ¥æµ‹è¯•SimpleChatGLM
    simple_test_result = test_simple_chatglm_directly()

    # æµ‹è¯•2: å®Œæ•´çŸ¥è¯†å›¾è°±å¢å¼ºæµç¨‹
    complete_test_results = test_complete_knowledge_graph_flow()

    print("\n" + "ğŸ¯" * 20)
    print("ğŸ¯ æœ€ç»ˆéªŒè¯ç»“æœ")
    print("ğŸ¯" * 20)

    if simple_test_result:
        print("âœ… SimpleChatGLMç›´æ¥è°ƒç”¨: æˆåŠŸ")
    else:
        print("âŒ SimpleChatGLMç›´æ¥è°ƒç”¨: å¤±è´¥")

    if complete_test_results:
        successful_complete = sum(1 for r in complete_test_results if r['success'])
        total_complete = len(complete_test_results)
        if successful_complete > 0:
            print(f"âœ… çŸ¥è¯†å›¾è°±å¢å¼ºæµç¨‹: {successful_complete}/{total_complete} æˆåŠŸ")
        else:
            print("âŒ çŸ¥è¯†å›¾è°±å¢å¼ºæµç¨‹: å…¨éƒ¨å¤±è´¥")
    else:
        print("âŒ çŸ¥è¯†å›¾è°±å¢å¼ºæµç¨‹: æ— æ³•è¿è¡Œ")

    # æœ€ç»ˆç»“è®º
    if simple_test_result and complete_test_results:
        print("\nğŸ‰ æ­å–œï¼ChatGLMæ™ºèƒ½å›å¤åŠŸèƒ½å·²å®Œå…¨ä¿®å¤ï¼")
        print("ğŸ‰ ç³»ç»Ÿç°åœ¨èƒ½å¤Ÿæä¾›çœŸæ­£çš„ChatGLMæ™ºèƒ½å›å¤è€Œéæ¨¡æ¿å“åº”ï¼")
    else:
        print("\nâš ï¸ éƒ¨åˆ†åŠŸèƒ½ä»éœ€æ”¹è¿›ï¼Œä½†åŸºç¡€æ¶æ„å·²ç»å®Œå–„")

if __name__ == "__main__":
    main()