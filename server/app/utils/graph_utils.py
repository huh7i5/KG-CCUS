import json
import re


def clean_text_for_json(text):
    """æ¸…ç†æ–‡æœ¬ä»¥ç¡®ä¿JSONåºåˆ—åŒ–å®‰å…¨"""
    if not isinstance(text, str):
        return text

    # ç§»é™¤æˆ–æ›¿æ¢é—®é¢˜å­—ç¬¦
    text = text.replace('\n', ' ')  # æ¢è¡Œç¬¦æ›¿æ¢ä¸ºç©ºæ ¼
    text = text.replace('\r', ' ')  # å›è½¦ç¬¦æ›¿æ¢ä¸ºç©ºæ ¼
    text = text.replace('\t', ' ')  # åˆ¶è¡¨ç¬¦æ›¿æ¢ä¸ºç©ºæ ¼
    text = text.replace('"', "'")   # åŒå¼•å·æ›¿æ¢ä¸ºå•å¼•å·

    # ç§»é™¤æ§åˆ¶å­—ç¬¦
    text = re.sub(r'[\x00-\x1f\x7f-\x9f]', '', text)

    # å‹ç¼©å¤šä¸ªç©ºæ ¼ä¸ºå•ä¸ªç©ºæ ¼
    text = re.sub(r'\s+', ' ', text)

    # ç§»é™¤é¦–å°¾ç©ºæ ¼
    text = text.strip()

    # é™åˆ¶é•¿åº¦é¿å…è¿‡é•¿çš„å®ä½“å
    if len(text) > 200:
        text = text[:197] + "..."

    return text

def search_node_item(user_input, lite_graph=None):
    """CCUSé¢†åŸŸçŸ¥è¯†å›¾è°±æ£€ç´¢åŠŸèƒ½"""
    import os

    # ç¡®ä¿æ­£ç¡®çš„æ•°æ®æ–‡ä»¶è·¯å¾„
    current_dir = os.path.dirname(os.path.abspath(__file__))
    data_path = os.path.join(current_dir, '..', '..', 'data', 'data.json')

    try:
        with open(data_path, 'r', encoding='utf-8') as f:
            data = json.load(f)
        print(f"ğŸ“Š Loaded knowledge graph with {len(data.get('nodes', []))} nodes and {len(data.get('links', []))} edges")
    except FileNotFoundError:
        print(f"âš ï¸  CCUS knowledge graph not found at {data_path}")
        return None
    except json.JSONDecodeError:
        print(f"âŒ Invalid JSON format in {data_path}")
        return None

    if lite_graph is None:
        lite_graph = {
            'nodes': [],
            'links': [],
            'sents': []
        }

    # CCUSé¢†åŸŸä¼˜åŒ–çš„æœç´¢ç­–ç•¥
    SEARCH_DEPTH = 2  # å¢åŠ æœç´¢æ·±åº¦ä»¥è·å–æ›´å¤šç›¸å…³ä¿¡æ¯

    # åˆå§‹æœç´¢èŠ‚ç‚¹
    search_terms = [user_input]

    # æ·»åŠ CCUSç›¸å…³çš„åŒä¹‰è¯æ‰©å±•
    ccus_synonyms = {
        'ccus': ['ç¢³æ•é›†åˆ©ç”¨ä¸å‚¨å­˜', 'ç¢³æ•é›†', 'ç¢³å‚¨å­˜', 'ç¢³åˆ©ç”¨'],
        'ccs': ['ç¢³æ•é›†ä¸å‚¨å­˜', 'ç¢³å°å­˜'],
        'ccu': ['ç¢³æ•é›†ä¸åˆ©ç”¨', 'ç¢³è½¬åŒ–'],
        'äºŒæ°§åŒ–ç¢³': ['co2', 'COâ‚‚', 'æ¸©å®¤æ°”ä½“'],
        'æ•é›†': ['æ•è·', 'åˆ†ç¦»', 'æ”¶é›†'],
        'å‚¨å­˜': ['å°å­˜', 'å‚¨è—', 'åœ°è´¨å‚¨å­˜'],
        'åˆ©ç”¨': ['è½¬åŒ–', 'åº”ç”¨', 'èµ„æºåŒ–']
    }

    user_lower = user_input.lower()
    for key, synonyms in ccus_synonyms.items():
        if key in user_lower:
            search_terms.extend(synonyms)

    print(f"ğŸ” CCUS graph search for: {user_input}")
    print(f"ğŸ“ Extended search terms: {search_terms}")

    found_nodes = set()

    for depth in range(SEARCH_DEPTH):
        new_search_terms = []

        for search_term in search_terms:
            for edge in data.get('links', []):
                try:
                    source_idx = int(edge['source'])
                    target_idx = int(edge['target'])

                    if source_idx >= len(data['nodes']) or target_idx >= len(data['nodes']):
                        continue

                    source = data['nodes'][source_idx].copy()
                    target = data['nodes'][target_idx].copy()

                    # æ”¹è¿›çš„åŒ¹é…ç­–ç•¥
                    source_match = _is_ccus_match(search_term, source['name'])
                    target_match = _is_ccus_match(search_term, target['name'])

                    if source_match or target_match:
                        # æ·»åŠ å¥å­ä¿¡æ¯
                        sent_key = str(edge.get('sent', ''))
                        if sent_key in data.get('sents', {}):
                            sent = data['sents'][sent_key]
                            if sent not in lite_graph['sents']:
                                edge_copy = edge.copy()
                                edge_copy['sent'] = len(lite_graph['sents'])
                                lite_graph['sents'].append(sent)
                            else:
                                edge_copy = edge.copy()
                                edge_copy['sent'] = lite_graph['sents'].index(sent)
                        else:
                            edge_copy = edge.copy()
                            edge_copy['sent'] = -1

                        # æ·»åŠ èŠ‚ç‚¹
                        source_id = _add_node_to_graph(source, lite_graph)
                        target_id = _add_node_to_graph(target, lite_graph)

                        # æ·»åŠ è¾¹
                        edge_copy['source'] = source_id
                        edge_copy['target'] = target_id

                        # é¿å…é‡å¤è¾¹
                        edge_exists = any(
                            link['source'] == edge_copy['source'] and
                            link['target'] == edge_copy['target'] and
                            link.get('name', '') == edge_copy.get('name', '')
                            for link in lite_graph['links']
                        )

                        if not edge_exists:
                            lite_graph['links'].append(edge_copy)

                        # æ”¶é›†ç›¸å…³èŠ‚ç‚¹ç”¨äºä¸‹ä¸€è½®æœç´¢
                        found_nodes.add(source['name'])
                        found_nodes.add(target['name'])

                except (KeyError, IndexError, ValueError) as e:
                    continue

        if depth < SEARCH_DEPTH - 1:
            # å‡†å¤‡ä¸‹ä¸€è½®æœç´¢çš„èŠ‚ç‚¹
            search_terms = list(found_nodes)[:10]  # é™åˆ¶æœç´¢èŠ‚ç‚¹æ•°é‡

        if len(lite_graph['nodes']) == 0:
            break

    print(f"âœ… CCUS graph search complete: {len(lite_graph['nodes'])} nodes, {len(lite_graph['links'])} edges")
    return lite_graph if len(lite_graph['nodes']) > 0 else None

def _is_ccus_match(search_term, node_name):
    """CCUSé¢†åŸŸçš„æ™ºèƒ½åŒ¹é…ç­–ç•¥"""
    if not search_term or not node_name:
        return False

    search_lower = search_term.lower().strip()
    node_lower = node_name.lower().strip()

    # 1. ç²¾ç¡®åŒ¹é…
    if search_lower == node_lower:
        return True

    # 2. åŒ…å«åŒ¹é…
    if search_lower in node_lower or node_lower in search_lower:
        return True

    # 3. CCUSç‰¹æ®ŠåŒ¹é…è§„åˆ™
    ccus_mappings = {
        'ccus': ['ç¢³æ•é›†åˆ©ç”¨ä¸å‚¨å­˜', 'ç¢³æ•é›†', 'äºŒæ°§åŒ–ç¢³'],
        'co2': ['äºŒæ°§åŒ–ç¢³', 'æ¸©å®¤æ°”ä½“', 'ç¢³'],
        'æ•é›†': ['capture', 'åˆ†ç¦»', 'æ”¶é›†'],
        'å‚¨å­˜': ['storage', 'å°å­˜', 'å‚¨è—'],
        'åˆ©ç”¨': ['utilization', 'è½¬åŒ–', 'åº”ç”¨']
    }

    for key, values in ccus_mappings.items():
        if key in search_lower:
            if any(v in node_lower for v in values):
                return True
        if any(v in search_lower for v in values):
            if key in node_lower:
                return True

    return False

def _add_node_to_graph(node, lite_graph):
    """æ·»åŠ èŠ‚ç‚¹åˆ°å›¾è°±ä¸­ï¼Œé¿å…é‡å¤"""
    for i, existing_node in enumerate(lite_graph['nodes']):
        if existing_node['name'] == node['name']:
            return i

    node_copy = node.copy()
    node_copy['id'] = len(lite_graph['nodes'])
    lite_graph['nodes'].append(node_copy)
    return node_copy['id']


def convert_graph_to_triples(graph, entity=None):
    """å°†å›¾è°±è½¬æ¢ä¸ºä¸‰å…ƒç»„æ ¼å¼ï¼Œå¹¶æ·»åŠ ç›¸å…³å¥å­ä¿¡æ¯"""
    triples = []
    for link in graph['links']:
        source = graph['nodes'][link['source']]
        target = graph['nodes'][link['target']]

        if entity is not None:
            if entity in source['name'] or entity in target['name']:
                triple = (source['name'], link["name"], target['name'])
                triples.append(triple)
        else:
            triple = (source['name'], link["name"], target['name'])
            triples.append(triple)

    return triples

def extract_knowledge_content(graph, entity=None):
    """æå–çŸ¥è¯†å†…å®¹ï¼ŒåŒ…æ‹¬ä¸‰å…ƒç»„å’Œç›¸å…³å¥å­"""
    if not graph or not graph.get('nodes'):
        return ""

    content_parts = []

    # æ·»åŠ å®ä½“ç›¸å…³çš„ä¸‰å…ƒç»„ä¿¡æ¯
    triples = convert_graph_to_triples(graph, entity)
    if triples:
        content_parts.append("ã€ç›¸å…³å…³ç³»ã€‘")
        for i, (subj, pred, obj) in enumerate(triples[:10]):  # é™åˆ¶æ•°é‡
            content_parts.append(f"{i+1}. {subj} {pred} {obj}")

    # æ·»åŠ ç›¸å…³å¥å­
    if graph.get('sents'):
        content_parts.append("\nã€ç›¸å…³æè¿°ã€‘")
        for i, sent in enumerate(graph['sents'][:5]):  # é™åˆ¶æ•°é‡
            content_parts.append(f"{i+1}. {sent}")

    return "\n".join(content_parts)

def get_entity_details(entity_name, graph=None):
    """è·å–å®ä½“çš„è¯¦ç»†ä¿¡æ¯"""
    if not graph:
        graph = search_node_item(entity_name)

    if not graph or not graph.get('nodes'):
        return None

    details = {
        "name": entity_name,
        "related_entities": [],
        "relationships": [],
        "sentences": graph.get('sents', []),
        "total_connections": 0
    }

    # æ‰¾åˆ°è¯¥å®ä½“çš„æ‰€æœ‰å…³ç³»
    for link in graph.get('links', []):
        source = graph['nodes'][link['source']]
        target = graph['nodes'][link['target']]
        relation = link.get('name', '')

        if entity_name in source['name'] or source['name'] in entity_name:
            details['relationships'].append({
                "type": "outgoing",
                "relation": relation,
                "target": target['name']
            })
            if target['name'] not in details['related_entities']:
                details['related_entities'].append(target['name'])

        elif entity_name in target['name'] or target['name'] in entity_name:
            details['relationships'].append({
                "type": "incoming",
                "relation": relation,
                "source": source['name']
            })
            if source['name'] not in details['related_entities']:
                details['related_entities'].append(source['name'])

    details['total_connections'] = len(details['relationships'])
    return details