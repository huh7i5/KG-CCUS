"""
å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨
å®ç°å¤šè½®ç­›é€‰å’Œå®ä½“è·Ÿè¸ªåŠŸèƒ½
"""

import json
from collections import defaultdict
from app.utils.graph_utils import search_node_item, get_entity_details


class ContextManager:
    """å¯¹è¯ä¸Šä¸‹æ–‡ç®¡ç†å™¨"""

    def __init__(self):
        self.conversation_entities = []  # å¯¹è¯ä¸­æåˆ°çš„å®ä½“
        self.entity_focus_history = []   # å®ä½“å…³æ³¨å†å²
        self.topic_context = {}          # è¯é¢˜ä¸Šä¸‹æ–‡
        self.last_graph = None           # ä¸Šæ¬¡æœç´¢çš„å›¾è°±

    def update_context(self, user_input, entities, graph):
        """æ›´æ–°å¯¹è¯ä¸Šä¸‹æ–‡"""
        print(f"ğŸ”„ Updating context with entities: {entities}")

        # æ›´æ–°å®ä½“åˆ—è¡¨
        for entity in entities:
            if entity not in self.conversation_entities:
                self.conversation_entities.append(entity)
                self.entity_focus_history.append({
                    "entity": entity,
                    "query": user_input,
                    "mentioned_count": 1
                })
            else:
                # å¢åŠ æåŠæ¬¡æ•°
                for item in self.entity_focus_history:
                    if item["entity"] == entity:
                        item["mentioned_count"] += 1
                        break

        # ä¿æŒæœ€è¿‘çš„å›¾è°±
        if graph:
            self.last_graph = graph

        # åˆ†æè¯é¢˜ä¸Šä¸‹æ–‡
        self._analyze_topic_context(user_input, entities)

        print(f"ğŸ“Š Context: {len(self.conversation_entities)} entities tracked")

    def _analyze_topic_context(self, user_input, entities):
        """åˆ†æè¯é¢˜ä¸Šä¸‹æ–‡"""
        # è¯†åˆ«é—®é¢˜ç±»å‹
        question_type = self._identify_question_type(user_input)

        # æ›´æ–°è¯é¢˜ä¸Šä¸‹æ–‡
        if question_type:
            self.topic_context.update({
                "current_question_type": question_type,
                "current_entities": entities,
                "last_query": user_input
            })

    def _identify_question_type(self, user_input):
        """è¯†åˆ«é—®é¢˜ç±»å‹"""
        query = user_input.lower()

        if any(word in query for word in ["æ˜¯ä»€ä¹ˆ", "ä»€ä¹ˆæ˜¯", "ä»‹ç»", "å®šä¹‰"]):
            return "definition"
        elif any(word in query for word in ["æœ‰å“ªäº›", "åŒ…æ‹¬", "ç§ç±»", "ç±»å‹"]):
            return "enumeration"
        elif any(word in query for word in ["å¦‚ä½•", "æ€ä¹ˆ", "æ–¹æ³•", "æ­¥éª¤"]):
            return "procedure"
        elif any(word in query for word in ["ä¸ºä»€ä¹ˆ", "åŸå› ", "ä½œç”¨", "ç›®çš„"]):
            return "explanation"
        elif any(word in query for word in ["å…³ç³»", "è”ç³»", "ç›¸å…³", "åŒºåˆ«"]):
            return "relationship"
        elif any(word in query for word in ["æ›´å¤š", "è¯¦ç»†", "å…·ä½“", "è¿›ä¸€æ­¥"]):
            return "elaboration"
        else:
            return "general"

    def get_focused_search(self, new_entities):
        """è·å–èšç„¦æœç´¢ç»“æœ"""
        if not self.conversation_entities and not new_entities:
            return None

        # åˆå¹¶å½“å‰å®ä½“å’Œå†å²å®ä½“
        all_entities = list(set(self.conversation_entities + new_entities))

        # æ„å»ºèšç„¦å›¾è°±
        focused_graph = None

        for entity in all_entities[:5]:  # é™åˆ¶å®ä½“æ•°é‡
            entity_graph = search_node_item(entity, focused_graph)
            if entity_graph:
                if not focused_graph:
                    focused_graph = entity_graph
                else:
                    # åˆå¹¶å›¾è°±
                    focused_graph = self._merge_graphs(focused_graph, entity_graph)

        return focused_graph

    def _merge_graphs(self, graph1, graph2):
        """åˆå¹¶ä¸¤ä¸ªå›¾è°±"""
        if not graph1:
            return graph2
        if not graph2:
            return graph1

        merged = {
            "nodes": graph1["nodes"].copy(),
            "links": graph1["links"].copy(),
            "sents": graph1["sents"].copy()
        }

        # åˆå¹¶èŠ‚ç‚¹
        existing_nodes = {node["name"]: node for node in merged["nodes"]}
        for node in graph2["nodes"]:
            if node["name"] not in existing_nodes:
                node["id"] = len(merged["nodes"])
                merged["nodes"].append(node)

        # åˆå¹¶é“¾æ¥
        for link in graph2["links"]:
            if link not in merged["links"]:
                merged["links"].append(link)

        # åˆå¹¶å¥å­
        for sent in graph2["sents"]:
            if sent not in merged["sents"]:
                merged["sents"].append(sent)

        return merged

    def get_context_aware_response_prefix(self, entities):
        """è·å–ä¸Šä¸‹æ–‡æ„ŸçŸ¥çš„å›ç­”å‰ç¼€"""
        if not self.conversation_entities:
            return ""

        # æ£€æŸ¥æ˜¯å¦æ˜¯å»¶ç»­æ€§é—®é¢˜
        if self.topic_context.get("current_question_type") == "elaboration":
            if self.conversation_entities:
                last_entities = ", ".join(self.conversation_entities[-2:])
                return f"åŸºäºå‰é¢è®¨è®ºçš„{last_entities}ï¼Œ"

        # æ£€æŸ¥æ˜¯å¦æœ‰é‡å¤æåŠçš„å®ä½“
        repeated_entities = []
        for item in self.entity_focus_history:
            if item["mentioned_count"] > 1:
                repeated_entities.append(item["entity"])

        if repeated_entities:
            return f"ç»§ç»­å…³äº{repeated_entities[0]}çš„è®¨è®ºï¼Œ"

        return ""

    def get_conversation_summary(self):
        """è·å–å¯¹è¯æ‘˜è¦"""
        if not self.conversation_entities:
            return None

        # ç»Ÿè®¡å®ä½“æåŠé¢‘ç‡
        entity_counts = defaultdict(int)
        for item in self.entity_focus_history:
            entity_counts[item["entity"]] = item["mentioned_count"]

        # æŒ‰é¢‘ç‡æ’åº
        sorted_entities = sorted(entity_counts.items(), key=lambda x: x[1], reverse=True)

        return {
            "total_entities": len(self.conversation_entities),
            "most_discussed": sorted_entities[:3],
            "current_topic": self.topic_context.get("current_question_type", "general"),
            "entities": self.conversation_entities
        }

    def suggest_related_questions(self, current_entities):
        """æ ¹æ®ä¸Šä¸‹æ–‡å»ºè®®ç›¸å…³é—®é¢˜"""
        if not current_entities:
            return []

        suggestions = []
        entity = current_entities[0] if current_entities else None

        if entity:
            # æ ¹æ®å®ä½“ç±»å‹å’Œä¸Šä¸‹æ–‡å»ºè®®é—®é¢˜
            if any(keyword in entity for keyword in ["ç­ç«å™¨", "æ¶ˆé˜²"]):
                suggestions = [
                    f"{entity}çš„å·¥ä½œåŸç†æ˜¯ä»€ä¹ˆï¼Ÿ",
                    f"{entity}æœ‰å“ªäº›ç±»å‹ï¼Ÿ",
                    f"å¦‚ä½•æ­£ç¡®ä½¿ç”¨{entity}ï¼Ÿ",
                    f"{entity}çš„ç»´æŠ¤ä¿å…»æ–¹æ³•ï¼Ÿ"
                ]
            elif any(keyword in entity for keyword in ["æ½œæ°´", "æ½œè‰‡"]):
                suggestions = [
                    f"{entity}è£…å¤‡åŒ…æ‹¬å“ªäº›ï¼Ÿ",
                    f"{entity}çš„å®‰å…¨æ³¨æ„äº‹é¡¹ï¼Ÿ",
                    f"{entity}æŠ€æœ¯å‘å±•å†ç¨‹ï¼Ÿ",
                    f"{entity}åœ¨å†›äº‹ä¸­çš„åº”ç”¨ï¼Ÿ"
                ]
            else:
                suggestions = [
                    f"{entity}çš„è¯¦ç»†ä»‹ç»ï¼Ÿ",
                    f"{entity}çš„ç›¸å…³æŠ€æœ¯ï¼Ÿ",
                    f"{entity}çš„åº”ç”¨é¢†åŸŸï¼Ÿ"
                ]

        return suggestions[:3]  # é™åˆ¶å»ºè®®æ•°é‡


# å…¨å±€ä¸Šä¸‹æ–‡ç®¡ç†å™¨å®ä¾‹
context_manager = ContextManager()