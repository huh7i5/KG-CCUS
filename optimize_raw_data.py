#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
CCUSæ–‡æœ¬æ•°æ®ä¼˜åŒ–è„šæœ¬
å°†çŸ­è¡Œåˆå¹¶ä¸ºé€‚åˆUIEæŠ½å–çš„é•¿å¥ï¼Œæé«˜æŠ½å–è´¨é‡å’Œæ•ˆç‡
"""

import re
import os

def clean_and_merge_text(input_file, output_file, min_length=80, max_length=300):
    """
    æ¸…ç†å’Œåˆå¹¶æ–‡æœ¬æ•°æ®

    Args:
        input_file: è¾“å…¥æ–‡ä»¶è·¯å¾„
        output_file: è¾“å‡ºæ–‡ä»¶è·¯å¾„
        min_length: æœ€å°å¥å­é•¿åº¦
        max_length: æœ€å¤§å¥å­é•¿åº¦
    """

    with open(input_file, 'r', encoding='utf-8') as f:
        lines = f.readlines()

    cleaned_lines = []
    current_paragraph = ""

    for line in lines:
        line = line.strip()

        # è·³è¿‡æ— æ•ˆè¡Œ
        if should_skip_line(line):
            continue

        # å¦‚æœæ˜¯æ®µè½åˆ†éš”ç¬¦æˆ–ç©ºè¡Œï¼Œä¿å­˜å½“å‰æ®µè½
        if is_paragraph_separator(line):
            if current_paragraph and len(current_paragraph) >= min_length:
                cleaned_lines.append(current_paragraph)
            current_paragraph = ""
            continue

        # ç´¯ç§¯å½“å‰æ®µè½
        if current_paragraph:
            # æ™ºèƒ½è¿æ¥ï¼šå¦‚æœå‰ä¸€å¥ä»¥æ ‡ç‚¹ç»“å°¾ï¼ŒåŠ å¥å·åˆ†éš”ï¼›å¦åˆ™ç›´æ¥è¿æ¥
            if current_paragraph[-1] in 'ã€‚ï¼ï¼Ÿï¼›':
                current_paragraph += " " + line
            else:
                current_paragraph += line
        else:
            current_paragraph = line

        # å¦‚æœæ®µè½å¤ªé•¿ï¼Œæˆªæ–­ä¿å­˜
        if len(current_paragraph) >= max_length:
            # å¯»æ‰¾åˆé€‚çš„æ–­ç‚¹ï¼ˆå¥å·ã€æ„Ÿå¹å·ç­‰ï¼‰
            break_point = find_break_point(current_paragraph, max_length)
            if break_point > min_length:
                cleaned_lines.append(current_paragraph[:break_point])
                current_paragraph = current_paragraph[break_point:].strip()

    # å¤„ç†æœ€åä¸€ä¸ªæ®µè½
    if current_paragraph and len(current_paragraph) >= min_length:
        cleaned_lines.append(current_paragraph)

    # ä¿å­˜æ¸…ç†åçš„æ•°æ®
    with open(output_file, 'w', encoding='utf-8') as f:
        for line in cleaned_lines:
            f.write(line + '\n')

    print(f"åŸå§‹è¡Œæ•°: {len(lines)}")
    print(f"æ¸…ç†åè¡Œæ•°: {len(cleaned_lines)}")
    print(f"æ•°æ®å‹ç¼©ç‡: {len(cleaned_lines)/len(lines)*100:.1f}%")

    # ç»Ÿè®¡è¡Œé•¿åº¦åˆ†å¸ƒ
    lengths = [len(line) for line in cleaned_lines]
    print(f"å¹³å‡è¡Œé•¿åº¦: {sum(lengths)/len(lengths):.1f}")
    print(f"æœ€çŸ­è¡Œé•¿åº¦: {min(lengths)}")
    print(f"æœ€é•¿è¡Œé•¿åº¦: {max(lengths)}")

    return cleaned_lines

def should_skip_line(line):
    """åˆ¤æ–­æ˜¯å¦åº”è¯¥è·³è¿‡è¿™ä¸€è¡Œ"""
    if not line:
        return True

    # è·³è¿‡æ— æ„ä¹‰çš„è¡Œ
    skip_patterns = [
        r'^=+$',  # åˆ†éš”ç¬¦
        r'^-+$',  # åˆ†éš”ç¬¦
        r'^æ–‡ä»¶:',  # æ–‡ä»¶ä¿¡æ¯
        r'^å¤„ç†æ—¶é—´:',  # å¤„ç†ä¿¡æ¯
        r'^æ–‡ä»¶å¤§å°:',  # æ–‡ä»¶ä¿¡æ¯
        r'^æ€»é¡µæ•°:',  # é¡µæ•°ä¿¡æ¯
        r'^æœ‰æ–‡æœ¬é¡µæ•°:',  # é¡µæ•°ä¿¡æ¯
        r'^æå–æ–¹æ³•:',  # æ–¹æ³•ä¿¡æ¯
        r'^=== ç¬¬ \d+ é¡µ ===$',  # é¡µç 
        r'^ç¬¬\d+é¡µ',  # é¡µç 
        r'^\d+$',  # çº¯æ•°å­—
        r'^[A-Z\s]+$',  # çº¯å¤§å†™å­—æ¯
        r'^GPUåŠ é€Ÿ',  # å¤„ç†ä¿¡æ¯
        r'^ç”Ÿæˆæ—¶é—´:',  # ç”Ÿæˆä¿¡æ¯
        r'^æºæ–‡ä»¶å¤¹:',  # æ–‡ä»¶å¤¹ä¿¡æ¯
        r'^æ€»æ–‡ä»¶æ•°:',  # æ–‡ä»¶æ•°ä¿¡æ¯
        r'^å¤„ç†ç¼–ç :',  # ç¼–ç ä¿¡æ¯
    ]

    for pattern in skip_patterns:
        if re.match(pattern, line):
            return True

    # è·³è¿‡å¤ªçŸ­çš„è¡Œï¼ˆé™¤éåŒ…å«é‡è¦ä¿¡æ¯ï¼‰
    if len(line) < 10 and not contains_important_info(line):
        return True

    return False

def contains_important_info(line):
    """åˆ¤æ–­çŸ­è¡Œæ˜¯å¦åŒ…å«é‡è¦ä¿¡æ¯"""
    important_keywords = [
        'CCUS', 'CCS', 'CO2', 'äºŒæ°§åŒ–ç¢³', 'ç¢³æ•é›†', 'ç¢³å°å­˜', 'ç¢³åˆ©ç”¨',
        'æŠ€æœ¯', 'æˆæœ¬', 'æ•ˆç‡', 'æ”¿ç­–', 'é¡¹ç›®', 'ä¼ä¸š', 'è¡Œä¸š',
        'æŠ•èµ„', 'ç»æµ', 'ç¯å¢ƒ', 'å®‰å…¨', 'é£é™©'
    ]

    return any(keyword in line for keyword in important_keywords)

def is_paragraph_separator(line):
    """åˆ¤æ–­æ˜¯å¦æ˜¯æ®µè½åˆ†éš”ç¬¦"""
    separators = [
        'æ‘˜è¦ï¼š', 'å…³é”®è¯ï¼š', 'ä¸­å›¾åˆ†ç±»å·ï¼š', 'æ–‡çŒ®æ ‡å¿—ç ï¼š',
        'åŸºé‡‘é¡¹ç›®ï¼š', 'ä½œè€…ç®€ä»‹ï¼š', 'é€šä¿¡ä½œè€…ï¼š', 'å¼•è¨€', 'ç»“è®º'
    ]

    return any(sep in line for sep in separators)

def find_break_point(text, max_length):
    """åœ¨åˆé€‚çš„ä½ç½®æ‰¾åˆ°æ–­ç‚¹"""
    if len(text) <= max_length:
        return len(text)

    # ä¼˜å…ˆåœ¨å¥å·ã€æ„Ÿå¹å·ã€é—®å·å¤„æ–­å¼€
    for i in range(max_length, max_length//2, -1):
        if text[i] in 'ã€‚ï¼ï¼Ÿ':
            return i + 1

    # å…¶æ¬¡åœ¨åˆ†å·ã€é€—å·å¤„æ–­å¼€
    for i in range(max_length, max_length//2, -1):
        if text[i] in 'ï¼›ï¼Œ':
            return i + 1

    # æœ€ååœ¨ç©ºæ ¼å¤„æ–­å¼€
    for i in range(max_length, max_length//2, -1):
        if text[i] == ' ':
            return i

    # å®åœ¨æ‰¾ä¸åˆ°åˆé€‚ä½ç½®å°±ç¡¬åˆ‡
    return max_length

if __name__ == "__main__":
    input_file = "data/raw_data.txt"
    output_file = "data/raw_data_optimized.txt"

    print("ğŸš€ å¼€å§‹ä¼˜åŒ–CCUSæ–‡æœ¬æ•°æ®...")

    cleaned_data = clean_and_merge_text(input_file, output_file)

    print("âœ… æ•°æ®ä¼˜åŒ–å®Œæˆï¼")
    print(f"ğŸ“ ä¼˜åŒ–åçš„æ–‡ä»¶ä¿å­˜ä¸º: {output_file}")
    print("\nğŸ“Š ä¼˜åŒ–æ•ˆæœé¢„è§ˆ:")

    # æ˜¾ç¤ºå‰5è¡Œç¤ºä¾‹
    for i, line in enumerate(cleaned_data[:5]):
        print(f"{i+1}. {line[:100]}{'...' if len(line) > 100 else ''}")

    print(f"\nğŸ’¡ å»ºè®®ä½¿ç”¨ä¼˜åŒ–åçš„æ–‡ä»¶è¿è¡ŒUIEæŠ½å–:")
    print(f"   python main.py --project=ccus_v1_optimized")